import { wrapGenerator, warn, isProgress, isMultiArgTensorProgress, processAndDisposeOfTensor, isSingleArgProgress, } from './utils';
import { parsePatchAndInputShapes, } from './model-utils';
import { scaleIncomingPixels, padInput, trimInput, scaleOutput, concatTensors, getCopyOfInput, } from './tensor-utils';
import { isTensor, isFourDimensionalTensor, } from '../../../shared/src/constants';
import { makeTick, } from './makeTick';
import { ERROR_INVALID_MODEL_PREDICTION, ERROR_INVALID_TENSOR_PREDICTED, WARNING_PROGRESS_WITHOUT_PATCH_SIZE, } from './errors-and-warnings';
import { getPatchesFromImage, } from './image-utils';
export const getPercentageComplete = (row, col, columns, total) => {
    const index = row * columns + col + 1;
    const percent = index / total;
    return percent;
};
export const executeModel = (model, pixels) => {
    const predictedPixels = model.predict(pixels);
    if (!isTensor(predictedPixels)) {
        throw new Error(ERROR_INVALID_MODEL_PREDICTION);
    }
    if (isFourDimensionalTensor(predictedPixels)) {
        return predictedPixels;
    }
    throw new Error(ERROR_INVALID_TENSOR_PREDICTED(predictedPixels.shape));
};
export async function* processPixels(tf, pixels, { output, progress, progressOutput, }, modelPackage, { originalImageSize, patchSize, padding = 0, }, { tensorAsBase64, }) {
    const { model, modelDefinition, } = modelPackage;
    const scale = modelDefinition.scale ?? 1;
    if (patchSize) {
        const [height, width,] = pixels.shape.slice(1);
        const patches = getPatchesFromImage([width, height,], patchSize, padding);
        yield;
        let upscaledTensor;
        const total = patches.length * patches[0].length;
        for (let rowIdx = 0; rowIdx < patches.length; rowIdx++) {
            const row = patches[rowIdx];
            const columns = row.length;
            let colTensor;
            yield [colTensor, upscaledTensor,];
            for (let colIdx = 0; colIdx < columns; colIdx++) {
                const { pre, post, } = row[colIdx];
                yield [upscaledTensor, colTensor,];
                const slicedPixels = pixels.slice([0, ...pre.origin,], [-1, ...pre.size,]);
                yield [upscaledTensor, colTensor, slicedPixels,];
                const prediction = executeModel(model, slicedPixels);
                slicedPixels.dispose();
                yield [upscaledTensor, colTensor, prediction,];
                const startSlice = [0, post.origin[0] * scale, post.origin[1] * scale,];
                const endSlice = [-1, post.size[0] * scale, post.size[1] * scale,];
                const slicedPrediction = prediction.slice(startSlice, endSlice);
                prediction.dispose();
                yield [upscaledTensor, colTensor, slicedPrediction,];
                const processedPrediction = processAndDisposeOfTensor(tf, slicedPrediction, modelDefinition.postprocess, scaleOutput(modelDefinition.outputRange));
                yield [upscaledTensor, colTensor, processedPrediction,];
                if (progress !== undefined && isProgress(progress)) {
                    const percent = getPercentageComplete(rowIdx, colIdx, columns, total);
                    if (isSingleArgProgress(progress)) {
                        progress(percent);
                    }
                    else {
                        const squeezedTensor = processedPrediction.squeeze();
                        const sliceData = {
                            row: rowIdx,
                            col: colIdx,
                            patchCoordinates: {
                                pre,
                                post,
                            },
                        };
                        if (isMultiArgTensorProgress(progress, output, progressOutput)) {
                            progress(percent, squeezedTensor, sliceData);
                        }
                        else {
                            const src = tensorAsBase64(tf, squeezedTensor);
                            squeezedTensor.dispose();
                            progress(percent, src, sliceData);
                        }
                    }
                }
                yield [upscaledTensor, colTensor, processedPrediction,];
                colTensor = concatTensors(tf, [colTensor, processedPrediction,], 2);
                processedPrediction.dispose();
                yield [upscaledTensor, colTensor,];
            }
            upscaledTensor = concatTensors(tf, [upscaledTensor, colTensor,], 1);
            colTensor.dispose();
            yield [upscaledTensor,];
        }
        const processedUpscaledTensor = processAndDisposeOfTensor(tf, upscaledTensor.clone(), trimInput(tf, originalImageSize, scale));
        upscaledTensor?.dispose();
        yield [processedUpscaledTensor,];
        const squeezedTensor = processedUpscaledTensor.squeeze();
        processedUpscaledTensor.dispose();
        return squeezedTensor;
    }
    if (progress) {
        warn(WARNING_PROGRESS_WITHOUT_PATCH_SIZE);
    }
    const prediction = executeModel(model, pixels);
    yield [prediction,];
    const postprocessedTensor = processAndDisposeOfTensor(tf, prediction.clone(), modelDefinition.postprocess, scaleOutput(modelDefinition.outputRange), trimInput(tf, originalImageSize, scale));
    prediction.dispose();
    yield [postprocessedTensor,];
    const squeezedTensor = postprocessedTensor.squeeze();
    postprocessedTensor.dispose();
    return squeezedTensor;
}
export async function* upscale(tf, input, args, modelPackage, { getImageAsTensor, tensorAsBase64, }) {
    const parsedInput = getCopyOfInput(input);
    const startingPixels = await getImageAsTensor(tf, parsedInput);
    yield startingPixels;
    const imageSize = startingPixels.shape;
    const { patchSize, padding, modelInputShape, } = parsePatchAndInputShapes(tf, modelPackage, args, imageSize);
    const preprocessedPixels = processAndDisposeOfTensor(tf, startingPixels, modelPackage.modelDefinition.preprocess, scaleIncomingPixels(tf, modelPackage.modelDefinition.inputRange), modelInputShape ? padInput(tf, modelInputShape) : undefined);
    yield preprocessedPixels;
    const gen = processPixels(tf, preprocessedPixels, {
        output: args.output,
        progressOutput: args.progressOutput,
        progress: args.progress,
    }, modelPackage, {
        originalImageSize: imageSize,
        patchSize,
        padding,
    }, {
        tensorAsBase64,
    });
    let result = await gen.next();
    yield result.value;
    while (!result.done) {
        result = await gen.next();
        if (Array.isArray(result.value)) {
            yield [...result.value, preprocessedPixels,];
        }
        else if (isTensor(result.value)) {
            yield [result.value, preprocessedPixels,];
        }
        else {
            yield preprocessedPixels;
        }
    }
    preprocessedPixels.dispose();
    const upscaledPixels = result.value;
    if (args.output === 'tensor') {
        return upscaledPixels;
    }
    const base64Src = tensorAsBase64(tf, upscaledPixels);
    upscaledPixels.dispose();
    return base64Src;
}
;
export async function cancellableUpscale(tf, input, { signal, awaitNextFrame, ...args }, internalArgs, { checkValidEnvironment, ...internalConfig }) {
    checkValidEnvironment(input, {
        output: args.output,
        progressOutput: args.progressOutput,
    });
    const tick = makeTick(tf, signal || internalArgs.signal, awaitNextFrame);
    await tick();
    const upscaledPixels = await wrapGenerator(upscale(tf, input, args, internalArgs, internalConfig), tick);
    await tick();
    return upscaledPixels;
}
